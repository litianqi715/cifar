{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n"
     ]
    }
   ],
   "source": [
    "##### train pytorch\n",
    "\n",
    "# import packages\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import PIL.Image as image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.cuda.set_device(1)\n",
    "from time import *\n",
    "import pdb\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "# training hyperparameters\n",
    "total_epoch = 15\n",
    "pre_epoch = 0\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "gpu_id = 1\n",
    "\n",
    "\n",
    "#### data\n",
    "# train_loader = torch.utils.data.DataLoader([train_data, train_labels], batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"/home/ltq/cifar/\", train=True, download=False, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "\n",
    "\n",
    "##### model\n",
    "# -resnet18\n",
    "resnet18 = models.resnet18(pretrained=False)\n",
    "resnet18.fc = nn.Linear(512, 10)\n",
    "\n",
    "# vgg16 = models.vgg16(pretrained=False)\n",
    "# vgg16.fc = nn.Linear(1000, 10)\n",
    "\n",
    "model = resnet18.cuda(gpu_id)\n",
    "model_name = \"resnet18\"\n",
    "\n",
    "\n",
    "# loss and optimizer\n",
    "getloss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# training\n",
    "best_acc = 85\n",
    "print(\"Starting training\")\n",
    "start_time = time()\n",
    "for epoch in range(pre_epoch, total_epoch):\n",
    "    print(\"epoch: {}\".format(epoch+1))\n",
    "    start_epoch = time()\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        length = len(train_loader)\n",
    "        inputs, labels = data\n",
    "        inputs = torch.autograd.Variable(inputs).cuda(gpu_id)\n",
    "        labels = torch.autograd.Variable(labels).cuda(gpu_id)\n",
    "#         print(inputs.shape, labels.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward\n",
    "        outputs = model(inputs)\n",
    "        loss = getloss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss and accuracy every epoch\n",
    "#         pdb.set_trace()\n",
    "        sum_loss += float(loss.data.cpu().numpy())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "        print('[epoch:%03d, iter:%05d] Loss: %.03f | Acc: %.3f%% | time: %010d '\n",
    "          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total, time() - start_epoch))\n",
    "    torch.save(model.state_dict(), open(\"state_{}_epoch{}.pth\".format(model_name, epoch+1), \"w\"))\n",
    "    print(\"epoch %03d, used time total: %010d\" % (epoch+1, time() - start_time))\n",
    "\n",
    "# classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### test model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### train model paddle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### compatibility of py2/py3\n",
    "if sys.version < str(3.0):\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            import cPickle\n",
    "            dict = cPickle.load(fo)\n",
    "        return dict\n",
    "else:\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            import pickle\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    \n",
    "##### compatibility of torch 0.3.1/0.4.1/1.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 3072), 1)\n",
      "((10000, 3072), 2)\n",
      "((10000, 3072), 3)\n",
      "(30000, 32, 32, 3)\n",
      "30000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6aadde3cafd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "##### forget function here\n",
    "\n",
    "files = [\"/home/ltq/cifar/cifar-10-batches-py/data_batch_1\", \n",
    "         \"/home/ltq/cifar/cifar-10-batches-py/data_batch_2\",\n",
    "#          \"/home/ltq/cifar/cifar-10-batches-py/data_batch_3\",\n",
    "#         \"/home/ltq/cifar/cifar-10-batches-py/data_batch_4\",\n",
    "        \"/home/ltq/cifar/cifar-10-batches-py/data_batch_5\"]\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "filenames = []\n",
    "for batch_file in files:\n",
    "    batch_data = unpickle(batch_file)\n",
    "    train_data.append(batch_data['data'])\n",
    "    train_labels += batch_data['labels']\n",
    "    filenames += batch_data['filenames']\n",
    "    print(batch_data['data'].shape, len(train_data))\n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_data = train_data.reshape(30000, 3, 32,32)\n",
    "train_data = train_data.transpose((0,2,3,1))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(len(train_labels))\n",
    "aa=np.array(train_labels)\n",
    "aa.shape\n",
    "aa.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n",
      "0.2.1\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-29:\n",
      "Process Process-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "Exception socket.error: error(2, 'No such file or directory') in <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7fa6a603bc90>> ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-828451d85f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### check data loader\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.cuda.set_device(1)\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# img = imgs[5003]\n",
    "# r = image.fromarray(img[0]).convert('L')\n",
    "# g = image.fromarray(img[1]).convert('L')\n",
    "# b = image.fromarray(img[2]).convert('L')\n",
    "# img_m = image.merge('RGB',(r,g,b))\n",
    "# img_m\n",
    "\n",
    "\n",
    "#### data\n",
    "# train_loader = torch.utils.data.DataLoader([train_data, train_labels], batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n",
    "#     torch.autograd.Variable(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"/home/ltq/cifar/\", train=True, download=False, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "print(type(train_loader))\n",
    "for i, data in enumerate(train_loader):\n",
    "    inputs, labels = data\n",
    "    print( torch.autograd.Variable(inputs).shape )\n",
    "    print( torch.autograd.Variable(labels).shape )\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n",
      "0.2.1\n",
      "Starting training\n",
      "epoch: 1\n",
      "[epoch:001, iter:00001] Loss: 2.472 | Acc: 6.250% | time: 0000000000 \n",
      "[epoch:001, iter:00002] Loss: 2.442 | Acc: 7.031% | time: 0000000000 \n",
      "[epoch:001, iter:00003] Loss: 2.404 | Acc: 9.375% | time: 0000000000 \n",
      "[epoch:001, iter:00004] Loss: 2.401 | Acc: 8.203% | time: 0000000000 \n",
      "[epoch:001, iter:00005] Loss: 2.383 | Acc: 8.438% | time: 0000000001 \n",
      "[epoch:001, iter:00006] Loss: 2.366 | Acc: 9.375% | time: 0000000001 \n",
      "[epoch:001, iter:00007] Loss: 2.361 | Acc: 10.714% | time: 0000000001 \n",
      "[epoch:001, iter:00008] Loss: 2.336 | Acc: 13.086% | time: 0000000001 \n",
      "[epoch:001, iter:00009] Loss: 2.354 | Acc: 12.674% | time: 0000000001 \n",
      "[epoch:001, iter:00010] Loss: 2.350 | Acc: 12.969% | time: 0000000001 \n",
      "[epoch:001, iter:00011] Loss: 2.339 | Acc: 13.494% | time: 0000000001 \n",
      "[epoch:001, iter:00012] Loss: 2.348 | Acc: 13.281% | time: 0000000001 \n",
      "[epoch:001, iter:00013] Loss: 2.336 | Acc: 13.582% | time: 0000000001 \n",
      "[epoch:001, iter:00014] Loss: 2.328 | Acc: 14.509% | time: 0000000002 \n",
      "[epoch:001, iter:00015] Loss: 2.320 | Acc: 15.000% | time: 0000000002 \n",
      "[epoch:001, iter:00016] Loss: 2.313 | Acc: 15.039% | time: 0000000002 \n",
      "[epoch:001, iter:00017] Loss: 2.305 | Acc: 15.074% | time: 0000000002 \n",
      "[epoch:001, iter:00018] Loss: 2.300 | Acc: 15.191% | time: 0000000002 \n",
      "[epoch:001, iter:00019] Loss: 2.292 | Acc: 15.789% | time: 0000000002 \n",
      "[epoch:001, iter:00020] Loss: 2.282 | Acc: 16.562% | time: 0000000002 \n",
      "[epoch:001, iter:00021] Loss: 2.265 | Acc: 17.336% | time: 0000000002 \n",
      "[epoch:001, iter:00022] Loss: 2.262 | Acc: 17.827% | time: 0000000002 \n",
      "[epoch:001, iter:00023] Loss: 2.262 | Acc: 18.003% | time: 0000000003 \n",
      "[epoch:001, iter:00024] Loss: 2.260 | Acc: 17.773% | time: 0000000003 \n",
      "[epoch:001, iter:00025] Loss: 2.247 | Acc: 18.062% | time: 0000000003 \n",
      "[epoch:001, iter:00026] Loss: 2.235 | Acc: 18.209% | time: 0000000003 \n",
      "[epoch:001, iter:00027] Loss: 2.228 | Acc: 18.345% | time: 0000000003 \n",
      "[epoch:001, iter:00028] Loss: 2.230 | Acc: 18.248% | time: 0000000003 \n",
      "[epoch:001, iter:00029] Loss: 2.227 | Acc: 18.373% | time: 0000000003 \n",
      "[epoch:001, iter:00030] Loss: 2.218 | Acc: 18.906% | time: 0000000003 \n",
      "[epoch:001, iter:00031] Loss: 2.216 | Acc: 19.052% | time: 0000000004 \n",
      "[epoch:001, iter:00032] Loss: 2.218 | Acc: 19.141% | time: 0000000004 \n",
      "[epoch:001, iter:00033] Loss: 2.218 | Acc: 19.034% | time: 0000000004 \n",
      "[epoch:001, iter:00034] Loss: 2.225 | Acc: 19.026% | time: 0000000004 \n",
      "[epoch:001, iter:00035] Loss: 2.220 | Acc: 19.062% | time: 0000000004 \n",
      "[epoch:001, iter:00036] Loss: 2.218 | Acc: 19.271% | time: 0000000004 \n",
      "[epoch:001, iter:00037] Loss: 2.219 | Acc: 19.257% | time: 0000000004 \n",
      "[epoch:001, iter:00038] Loss: 2.215 | Acc: 19.449% | time: 0000000004 \n",
      "[epoch:001, iter:00039] Loss: 2.211 | Acc: 19.551% | time: 0000000004 \n",
      "[epoch:001, iter:00040] Loss: 2.207 | Acc: 19.531% | time: 0000000005 \n",
      "[epoch:001, iter:00041] Loss: 2.203 | Acc: 19.512% | time: 0000000005 \n",
      "[epoch:001, iter:00042] Loss: 2.197 | Acc: 19.717% | time: 0000000005 \n",
      "[epoch:001, iter:00043] Loss: 2.197 | Acc: 19.695% | time: 0000000005 \n",
      "[epoch:001, iter:00044] Loss: 2.193 | Acc: 19.851% | time: 0000000005 \n",
      "[epoch:001, iter:00045] Loss: 2.190 | Acc: 20.000% | time: 0000000005 \n",
      "[epoch:001, iter:00046] Loss: 2.189 | Acc: 20.041% | time: 0000000005 \n",
      "[epoch:001, iter:00047] Loss: 2.191 | Acc: 19.980% | time: 0000000005 \n",
      "[epoch:001, iter:00048] Loss: 2.183 | Acc: 20.215% | time: 0000000006 \n",
      "[epoch:001, iter:00049] Loss: 2.180 | Acc: 20.504% | time: 0000000006 \n",
      "[epoch:001, iter:00050] Loss: 2.173 | Acc: 20.719% | time: 0000000006 \n",
      "[epoch:001, iter:00051] Loss: 2.165 | Acc: 21.048% | time: 0000000006 \n",
      "[epoch:001, iter:00052] Loss: 2.164 | Acc: 21.034% | time: 0000000006 \n",
      "[epoch:001, iter:00053] Loss: 2.161 | Acc: 20.991% | time: 0000000006 \n",
      "[epoch:001, iter:00054] Loss: 2.152 | Acc: 21.325% | time: 0000000006 \n",
      "[epoch:001, iter:00055] Loss: 2.151 | Acc: 21.392% | time: 0000000006 \n",
      "[epoch:001, iter:00056] Loss: 2.149 | Acc: 21.429% | time: 0000000006 \n",
      "[epoch:001, iter:00057] Loss: 2.144 | Acc: 21.464% | time: 0000000007 \n",
      "[epoch:001, iter:00058] Loss: 2.142 | Acc: 21.444% | time: 0000000007 \n",
      "[epoch:001, iter:00059] Loss: 2.138 | Acc: 21.504% | time: 0000000007 \n",
      "[epoch:001, iter:00060] Loss: 2.135 | Acc: 21.667% | time: 0000000007 \n",
      "[epoch:001, iter:00061] Loss: 2.130 | Acc: 21.849% | time: 0000000007 \n",
      "[epoch:001, iter:00062] Loss: 2.126 | Acc: 22.001% | time: 0000000007 \n",
      "[epoch:001, iter:00063] Loss: 2.124 | Acc: 22.098% | time: 0000000007 \n",
      "[epoch:001, iter:00064] Loss: 2.120 | Acc: 22.144% | time: 0000000007 \n",
      "[epoch:001, iter:00065] Loss: 2.117 | Acc: 22.308% | time: 0000000007 \n",
      "[epoch:001, iter:00066] Loss: 2.116 | Acc: 22.396% | time: 0000000008 \n",
      "[epoch:001, iter:00067] Loss: 2.118 | Acc: 22.295% | time: 0000000008 \n",
      "[epoch:001, iter:00068] Loss: 2.113 | Acc: 22.403% | time: 0000000008 \n",
      "[epoch:001, iter:00069] Loss: 2.110 | Acc: 22.509% | time: 0000000008 \n",
      "[epoch:001, iter:00070] Loss: 2.109 | Acc: 22.567% | time: 0000000008 \n",
      "[epoch:001, iter:00071] Loss: 2.104 | Acc: 22.689% | time: 0000000008 \n",
      "[epoch:001, iter:00072] Loss: 2.103 | Acc: 22.743% | time: 0000000008 \n",
      "[epoch:001, iter:00073] Loss: 2.102 | Acc: 22.795% | time: 0000000008 \n",
      "[epoch:001, iter:00074] Loss: 2.099 | Acc: 22.952% | time: 0000000009 \n",
      "[epoch:001, iter:00075] Loss: 2.096 | Acc: 23.042% | time: 0000000009 \n",
      "[epoch:001, iter:00076] Loss: 2.094 | Acc: 23.232% | time: 0000000009 \n",
      "[epoch:001, iter:00077] Loss: 2.093 | Acc: 23.214% | time: 0000000009 \n",
      "[epoch:001, iter:00078] Loss: 2.089 | Acc: 23.357% | time: 0000000009 \n",
      "[epoch:001, iter:00079] Loss: 2.087 | Acc: 23.438% | time: 0000000009 \n",
      "[epoch:001, iter:00080] Loss: 2.084 | Acc: 23.457% | time: 0000000009 \n",
      "[epoch:001, iter:00081] Loss: 2.080 | Acc: 23.553% | time: 0000000009 \n",
      "[epoch:001, iter:00082] Loss: 2.076 | Acc: 23.666% | time: 0000000009 \n",
      "[epoch:001, iter:00083] Loss: 2.074 | Acc: 23.795% | time: 0000000010 \n",
      "[epoch:001, iter:00084] Loss: 2.070 | Acc: 23.921% | time: 0000000010 \n",
      "[epoch:001, iter:00085] Loss: 2.068 | Acc: 23.934% | time: 0000000010 \n",
      "[epoch:001, iter:00086] Loss: 2.064 | Acc: 24.055% | time: 0000000010 \n",
      "[epoch:001, iter:00087] Loss: 2.061 | Acc: 24.156% | time: 0000000010 \n",
      "[epoch:001, iter:00088] Loss: 2.057 | Acc: 24.325% | time: 0000000010 \n",
      "[epoch:001, iter:00089] Loss: 2.053 | Acc: 24.386% | time: 0000000010 \n",
      "[epoch:001, iter:00090] Loss: 2.050 | Acc: 24.462% | time: 0000000010 \n",
      "[epoch:001, iter:00091] Loss: 2.049 | Acc: 24.519% | time: 0000000011 \n",
      "[epoch:001, iter:00092] Loss: 2.045 | Acc: 24.609% | time: 0000000011 \n",
      "[epoch:001, iter:00093] Loss: 2.040 | Acc: 24.866% | time: 0000000011 \n",
      "[epoch:001, iter:00094] Loss: 2.036 | Acc: 24.884% | time: 0000000011 \n",
      "[epoch:001, iter:00095] Loss: 2.035 | Acc: 24.934% | time: 0000000011 \n",
      "[epoch:001, iter:00096] Loss: 2.033 | Acc: 25.016% | time: 0000000011 \n",
      "[epoch:001, iter:00097] Loss: 2.034 | Acc: 24.968% | time: 0000000011 \n",
      "[epoch:001, iter:00098] Loss: 2.034 | Acc: 24.936% | time: 0000000011 \n",
      "[epoch:001, iter:00099] Loss: 2.034 | Acc: 24.937% | time: 0000000011 \n",
      "[epoch:001, iter:00100] Loss: 2.032 | Acc: 24.938% | time: 0000000012 \n",
      "[epoch:001, iter:00101] Loss: 2.027 | Acc: 25.139% | time: 0000000012 \n",
      "[epoch:001, iter:00102] Loss: 2.024 | Acc: 25.291% | time: 0000000012 \n",
      "[epoch:001, iter:00103] Loss: 2.026 | Acc: 25.273% | time: 0000000012 \n",
      "[epoch:001, iter:00104] Loss: 2.024 | Acc: 25.331% | time: 0000000012 \n",
      "[epoch:001, iter:00105] Loss: 2.027 | Acc: 25.357% | time: 0000000012 \n",
      "[epoch:001, iter:00106] Loss: 2.026 | Acc: 25.354% | time: 0000000012 \n",
      "[epoch:001, iter:00107] Loss: 2.025 | Acc: 25.423% | time: 0000000012 \n",
      "[epoch:001, iter:00108] Loss: 2.022 | Acc: 25.477% | time: 0000000012 \n",
      "[epoch:001, iter:00109] Loss: 2.024 | Acc: 25.487% | time: 0000000013 \n",
      "[epoch:001, iter:00110] Loss: 2.023 | Acc: 25.511% | time: 0000000013 \n",
      "[epoch:001, iter:00111] Loss: 2.023 | Acc: 25.549% | time: 0000000013 \n",
      "[epoch:001, iter:00112] Loss: 2.020 | Acc: 25.698% | time: 0000000013 \n",
      "[epoch:001, iter:00113] Loss: 2.018 | Acc: 25.719% | time: 0000000013 \n",
      "[epoch:001, iter:00114] Loss: 2.017 | Acc: 25.754% | time: 0000000013 \n",
      "[epoch:001, iter:00115] Loss: 2.016 | Acc: 25.802% | time: 0000000013 \n",
      "[epoch:001, iter:00116] Loss: 2.016 | Acc: 25.876% | time: 0000000013 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:001, iter:00117] Loss: 2.013 | Acc: 25.962% | time: 0000000014 \n",
      "[epoch:001, iter:00118] Loss: 2.011 | Acc: 25.993% | time: 0000000014 \n",
      "[epoch:001, iter:00119] Loss: 2.010 | Acc: 26.064% | time: 0000000014 \n",
      "[epoch:001, iter:00120] Loss: 2.007 | Acc: 26.120% | time: 0000000014 \n",
      "[epoch:001, iter:00121] Loss: 2.004 | Acc: 26.240% | time: 0000000014 \n",
      "[epoch:001, iter:00122] Loss: 2.000 | Acc: 26.370% | time: 0000000014 \n",
      "[epoch:001, iter:00123] Loss: 1.998 | Acc: 26.486% | time: 0000000014 \n",
      "[epoch:001, iter:00124] Loss: 1.996 | Acc: 26.613% | time: 0000000014 \n",
      "[epoch:001, iter:00125] Loss: 1.995 | Acc: 26.637% | time: 0000000014 \n",
      "[epoch:001, iter:00126] Loss: 1.993 | Acc: 26.724% | time: 0000000015 \n",
      "[epoch:001, iter:00127] Loss: 1.990 | Acc: 26.772% | time: 0000000015 \n",
      "[epoch:001, iter:00128] Loss: 1.987 | Acc: 26.843% | time: 0000000015 \n",
      "[epoch:001, iter:00129] Loss: 1.985 | Acc: 26.890% | time: 0000000015 \n",
      "[epoch:001, iter:00130] Loss: 1.983 | Acc: 26.899% | time: 0000000015 \n",
      "[epoch:001, iter:00131] Loss: 1.980 | Acc: 27.040% | time: 0000000015 \n",
      "[epoch:001, iter:00132] Loss: 1.978 | Acc: 27.154% | time: 0000000015 \n",
      "[epoch:001, iter:00133] Loss: 1.976 | Acc: 27.162% | time: 0000000015 \n",
      "[epoch:001, iter:00134] Loss: 1.972 | Acc: 27.332% | time: 0000000015 \n",
      "[epoch:001, iter:00135] Loss: 1.971 | Acc: 27.338% | time: 0000000016 \n",
      "[epoch:001, iter:00136] Loss: 1.968 | Acc: 27.401% | time: 0000000016 \n",
      "[epoch:001, iter:00137] Loss: 1.966 | Acc: 27.498% | time: 0000000016 \n",
      "[epoch:001, iter:00138] Loss: 1.963 | Acc: 27.604% | time: 0000000016 \n",
      "[epoch:001, iter:00139] Loss: 1.960 | Acc: 27.664% | time: 0000000016 \n",
      "[epoch:001, iter:00140] Loss: 1.958 | Acc: 27.757% | time: 0000000016 \n",
      "[epoch:001, iter:00141] Loss: 1.955 | Acc: 27.826% | time: 0000000016 \n",
      "[epoch:001, iter:00142] Loss: 1.954 | Acc: 27.839% | time: 0000000016 \n",
      "[epoch:001, iter:00143] Loss: 1.953 | Acc: 27.885% | time: 0000000017 \n",
      "[epoch:001, iter:00144] Loss: 1.952 | Acc: 27.984% | time: 0000000017 \n",
      "[epoch:001, iter:00145] Loss: 1.951 | Acc: 28.039% | time: 0000000017 \n",
      "[epoch:001, iter:00146] Loss: 1.949 | Acc: 28.104% | time: 0000000017 \n",
      "[epoch:001, iter:00147] Loss: 1.948 | Acc: 28.104% | time: 0000000017 \n",
      "[epoch:001, iter:00148] Loss: 1.945 | Acc: 28.178% | time: 0000000017 \n",
      "[epoch:001, iter:00149] Loss: 1.944 | Acc: 28.251% | time: 0000000017 \n",
      "[epoch:001, iter:00150] Loss: 1.943 | Acc: 28.271% | time: 0000000017 \n",
      "[epoch:001, iter:00151] Loss: 1.943 | Acc: 28.270% | time: 0000000017 \n",
      "[epoch:001, iter:00152] Loss: 1.940 | Acc: 28.403% | time: 0000000018 \n",
      "[epoch:001, iter:00153] Loss: 1.939 | Acc: 28.411% | time: 0000000018 \n",
      "[epoch:001, iter:00154] Loss: 1.939 | Acc: 28.409% | time: 0000000018 \n",
      "[epoch:001, iter:00155] Loss: 1.937 | Acc: 28.498% | time: 0000000018 \n",
      "[epoch:001, iter:00156] Loss: 1.934 | Acc: 28.626% | time: 0000000018 \n",
      "[epoch:001, iter:00157] Loss: 1.932 | Acc: 28.682% | time: 0000000018 \n",
      "[epoch:001, iter:00158] Loss: 1.930 | Acc: 28.728% | time: 0000000018 \n",
      "[epoch:001, iter:00159] Loss: 1.930 | Acc: 28.724% | time: 0000000018 \n",
      "[epoch:001, iter:00160] Loss: 1.929 | Acc: 28.770% | time: 0000000019 \n",
      "[epoch:001, iter:00161] Loss: 1.927 | Acc: 28.756% | time: 0000000019 \n",
      "[epoch:001, iter:00162] Loss: 1.926 | Acc: 28.800% | time: 0000000019 \n",
      "[epoch:001, iter:00163] Loss: 1.925 | Acc: 28.844% | time: 0000000019 \n",
      "[epoch:001, iter:00164] Loss: 1.924 | Acc: 28.830% | time: 0000000019 \n",
      "[epoch:001, iter:00165] Loss: 1.922 | Acc: 28.920% | time: 0000000019 \n",
      "[epoch:001, iter:00166] Loss: 1.920 | Acc: 28.963% | time: 0000000019 \n",
      "[epoch:001, iter:00167] Loss: 1.919 | Acc: 28.967% | time: 0000000019 \n",
      "[epoch:001, iter:00168] Loss: 1.916 | Acc: 29.064% | time: 0000000019 \n",
      "[epoch:001, iter:00169] Loss: 1.914 | Acc: 29.114% | time: 0000000020 \n",
      "[epoch:001, iter:00170] Loss: 1.911 | Acc: 29.219% | time: 0000000020 \n",
      "[epoch:001, iter:00171] Loss: 1.910 | Acc: 29.276% | time: 0000000020 \n",
      "[epoch:001, iter:00172] Loss: 1.910 | Acc: 29.315% | time: 0000000020 \n",
      "[epoch:001, iter:00173] Loss: 1.908 | Acc: 29.389% | time: 0000000020 \n",
      "[epoch:001, iter:00174] Loss: 1.906 | Acc: 29.454% | time: 0000000020 \n",
      "[epoch:001, iter:00175] Loss: 1.905 | Acc: 29.491% | time: 0000000020 \n",
      "[epoch:001, iter:00176] Loss: 1.904 | Acc: 29.528% | time: 0000000020 \n",
      "[epoch:001, iter:00177] Loss: 1.905 | Acc: 29.537% | time: 0000000020 \n",
      "[epoch:001, iter:00178] Loss: 1.902 | Acc: 29.644% | time: 0000000021 \n",
      "[epoch:001, iter:00179] Loss: 1.901 | Acc: 29.661% | time: 0000000021 \n",
      "[epoch:001, iter:00180] Loss: 1.901 | Acc: 29.644% | time: 0000000021 \n",
      "[epoch:001, iter:00181] Loss: 1.899 | Acc: 29.731% | time: 0000000021 \n",
      "[epoch:001, iter:00182] Loss: 1.897 | Acc: 29.833% | time: 0000000021 \n",
      "[epoch:001, iter:00183] Loss: 1.895 | Acc: 29.901% | time: 0000000021 \n",
      "[epoch:001, iter:00184] Loss: 1.893 | Acc: 29.959% | time: 0000000021 \n",
      "[epoch:001, iter:00185] Loss: 1.893 | Acc: 29.983% | time: 0000000021 \n",
      "[epoch:001, iter:00186] Loss: 1.892 | Acc: 29.990% | time: 0000000022 \n",
      "[epoch:001, iter:00187] Loss: 1.890 | Acc: 30.038% | time: 0000000022 \n",
      "[epoch:001, iter:00188] Loss: 1.889 | Acc: 30.078% | time: 0000000022 \n",
      "[epoch:001, iter:00189] Loss: 1.888 | Acc: 30.126% | time: 0000000022 \n",
      "[epoch:001, iter:00190] Loss: 1.886 | Acc: 30.173% | time: 0000000022 \n",
      "[epoch:001, iter:00191] Loss: 1.885 | Acc: 30.236% | time: 0000000022 \n",
      "[epoch:001, iter:00192] Loss: 1.885 | Acc: 30.249% | time: 0000000022 \n",
      "[epoch:001, iter:00193] Loss: 1.883 | Acc: 30.351% | time: 0000000022 \n",
      "[epoch:001, iter:00194] Loss: 1.882 | Acc: 30.420% | time: 0000000022 \n",
      "[epoch:001, iter:00195] Loss: 1.880 | Acc: 30.465% | time: 0000000023 \n",
      "[epoch:001, iter:00196] Loss: 1.880 | Acc: 30.485% | time: 0000000023 \n",
      "[epoch:001, iter:00197] Loss: 1.879 | Acc: 30.520% | time: 0000000023 \n",
      "[epoch:001, iter:00198] Loss: 1.878 | Acc: 30.548% | time: 0000000023 \n",
      "[epoch:001, iter:00199] Loss: 1.878 | Acc: 30.567% | time: 0000000023 \n",
      "[epoch:001, iter:00200] Loss: 1.877 | Acc: 30.602% | time: 0000000023 \n",
      "[epoch:001, iter:00201] Loss: 1.876 | Acc: 30.636% | time: 0000000023 \n",
      "[epoch:001, iter:00202] Loss: 1.876 | Acc: 30.608% | time: 0000000023 \n",
      "[epoch:001, iter:00203] Loss: 1.874 | Acc: 30.680% | time: 0000000024 \n",
      "[epoch:001, iter:00204] Loss: 1.873 | Acc: 30.744% | time: 0000000024 \n",
      "[epoch:001, iter:00205] Loss: 1.872 | Acc: 30.777% | time: 0000000024 \n",
      "[epoch:001, iter:00206] Loss: 1.871 | Acc: 30.833% | time: 0000000024 \n",
      "[epoch:001, iter:00207] Loss: 1.871 | Acc: 30.857% | time: 0000000024 \n",
      "[epoch:001, iter:00208] Loss: 1.872 | Acc: 30.859% | time: 0000000024 \n",
      "[epoch:001, iter:00209] Loss: 1.871 | Acc: 30.869% | time: 0000000024 \n",
      "[epoch:001, iter:00210] Loss: 1.872 | Acc: 30.826% | time: 0000000024 \n",
      "[epoch:001, iter:00211] Loss: 1.872 | Acc: 30.835% | time: 0000000024 \n",
      "[epoch:001, iter:00212] Loss: 1.870 | Acc: 30.867% | time: 0000000025 \n",
      "[epoch:001, iter:00213] Loss: 1.869 | Acc: 30.898% | time: 0000000025 \n",
      "[epoch:001, iter:00214] Loss: 1.868 | Acc: 30.936% | time: 0000000025 \n",
      "[epoch:001, iter:00215] Loss: 1.866 | Acc: 31.010% | time: 0000000025 \n",
      "[epoch:001, iter:00216] Loss: 1.865 | Acc: 31.069% | time: 0000000025 \n",
      "[epoch:001, iter:00217] Loss: 1.864 | Acc: 31.135% | time: 0000000025 \n",
      "[epoch:001, iter:00218] Loss: 1.863 | Acc: 31.185% | time: 0000000025 \n",
      "[epoch:001, iter:00219] Loss: 1.862 | Acc: 31.221% | time: 0000000025 \n",
      "[epoch:001, iter:00220] Loss: 1.862 | Acc: 31.236% | time: 0000000026 \n",
      "[epoch:001, iter:00221] Loss: 1.862 | Acc: 31.229% | time: 0000000026 \n",
      "[epoch:001, iter:00222] Loss: 1.862 | Acc: 31.229% | time: 0000000026 \n",
      "[epoch:001, iter:00223] Loss: 1.860 | Acc: 31.243% | time: 0000000026 \n",
      "[epoch:001, iter:00224] Loss: 1.860 | Acc: 31.243% | time: 0000000026 \n",
      "[epoch:001, iter:00225] Loss: 1.861 | Acc: 31.257% | time: 0000000026 \n",
      "[epoch:001, iter:00226] Loss: 1.859 | Acc: 31.285% | time: 0000000026 \n",
      "[epoch:001, iter:00227] Loss: 1.857 | Acc: 31.339% | time: 0000000026 \n",
      "[epoch:001, iter:00228] Loss: 1.856 | Acc: 31.401% | time: 0000000026 \n",
      "[epoch:001, iter:00229] Loss: 1.856 | Acc: 31.434% | time: 0000000027 \n",
      "[epoch:001, iter:00230] Loss: 1.854 | Acc: 31.515% | time: 0000000027 \n",
      "[epoch:001, iter:00231] Loss: 1.853 | Acc: 31.554% | time: 0000000027 \n",
      "[epoch:001, iter:00232] Loss: 1.852 | Acc: 31.580% | time: 0000000027 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:001, iter:00233] Loss: 1.851 | Acc: 31.565% | time: 0000000027 \n",
      "[epoch:001, iter:00234] Loss: 1.850 | Acc: 31.624% | time: 0000000027 \n",
      "[epoch:001, iter:00235] Loss: 1.850 | Acc: 31.642% | time: 0000000027 \n",
      "[epoch:001, iter:00236] Loss: 1.848 | Acc: 31.713% | time: 0000000027 \n",
      "[epoch:001, iter:00237] Loss: 1.847 | Acc: 31.731% | time: 0000000027 \n",
      "[epoch:001, iter:00238] Loss: 1.845 | Acc: 31.788% | time: 0000000028 \n",
      "[epoch:001, iter:00239] Loss: 1.844 | Acc: 31.838% | time: 0000000028 \n",
      "[epoch:001, iter:00240] Loss: 1.845 | Acc: 31.868% | time: 0000000028 \n",
      "[epoch:001, iter:00241] Loss: 1.845 | Acc: 31.918% | time: 0000000028 \n",
      "[epoch:001, iter:00242] Loss: 1.843 | Acc: 31.973% | time: 0000000028 \n",
      "[epoch:001, iter:00243] Loss: 1.842 | Acc: 32.047% | time: 0000000028 \n",
      "[epoch:001, iter:00244] Loss: 1.842 | Acc: 32.038% | time: 0000000028 \n",
      "[epoch:001, iter:00245] Loss: 1.840 | Acc: 32.085% | time: 0000000028 \n",
      "[epoch:001, iter:00246] Loss: 1.839 | Acc: 32.127% | time: 0000000029 \n",
      "[epoch:001, iter:00247] Loss: 1.838 | Acc: 32.155% | time: 0000000029 \n",
      "[epoch:001, iter:00248] Loss: 1.838 | Acc: 32.182% | time: 0000000029 \n",
      "[epoch:001, iter:00249] Loss: 1.837 | Acc: 32.248% | time: 0000000029 \n",
      "[epoch:001, iter:00250] Loss: 1.837 | Acc: 32.263% | time: 0000000029 \n",
      "[epoch:001, iter:00251] Loss: 1.836 | Acc: 32.290% | time: 0000000029 \n",
      "[epoch:001, iter:00252] Loss: 1.835 | Acc: 32.310% | time: 0000000029 \n",
      "[epoch:001, iter:00253] Loss: 1.834 | Acc: 32.349% | time: 0000000029 \n",
      "[epoch:001, iter:00254] Loss: 1.833 | Acc: 32.406% | time: 0000000029 \n",
      "[epoch:001, iter:00255] Loss: 1.832 | Acc: 32.402% | time: 0000000030 \n",
      "[epoch:001, iter:00256] Loss: 1.830 | Acc: 32.452% | time: 0000000030 \n",
      "[epoch:001, iter:00257] Loss: 1.830 | Acc: 32.484% | time: 0000000030 \n",
      "[epoch:001, iter:00258] Loss: 1.830 | Acc: 32.504% | time: 0000000030 \n",
      "[epoch:001, iter:00259] Loss: 1.828 | Acc: 32.577% | time: 0000000030 \n",
      "[epoch:001, iter:00260] Loss: 1.827 | Acc: 32.638% | time: 0000000030 \n",
      "[epoch:001, iter:00261] Loss: 1.826 | Acc: 32.645% | time: 0000000030 \n",
      "[epoch:001, iter:00262] Loss: 1.825 | Acc: 32.693% | time: 0000000030 \n",
      "[epoch:001, iter:00263] Loss: 1.824 | Acc: 32.723% | time: 0000000031 \n",
      "[epoch:001, iter:00264] Loss: 1.822 | Acc: 32.747% | time: 0000000031 \n",
      "[epoch:001, iter:00265] Loss: 1.823 | Acc: 32.765% | time: 0000000031 \n",
      "[epoch:001, iter:00266] Loss: 1.823 | Acc: 32.736% | time: 0000000031 \n",
      "[epoch:001, iter:00267] Loss: 1.821 | Acc: 32.766% | time: 0000000031 \n",
      "[epoch:001, iter:00268] Loss: 1.821 | Acc: 32.824% | time: 0000000031 \n",
      "[epoch:001, iter:00269] Loss: 1.821 | Acc: 32.842% | time: 0000000031 \n",
      "[epoch:001, iter:00270] Loss: 1.820 | Acc: 32.859% | time: 0000000031 \n",
      "[epoch:001, iter:00271] Loss: 1.820 | Acc: 32.859% | time: 0000000031 \n",
      "[epoch:001, iter:00272] Loss: 1.819 | Acc: 32.899% | time: 0000000032 \n",
      "[epoch:001, iter:00273] Loss: 1.819 | Acc: 32.898% | time: 0000000032 \n",
      "[epoch:001, iter:00274] Loss: 1.818 | Acc: 32.927% | time: 0000000032 \n",
      "[epoch:001, iter:00275] Loss: 1.817 | Acc: 32.960% | time: 0000000032 \n",
      "[epoch:001, iter:00276] Loss: 1.816 | Acc: 32.977% | time: 0000000032 \n",
      "[epoch:001, iter:00277] Loss: 1.815 | Acc: 33.004% | time: 0000000032 \n",
      "[epoch:001, iter:00278] Loss: 1.815 | Acc: 33.004% | time: 0000000032 \n",
      "[epoch:001, iter:00279] Loss: 1.814 | Acc: 33.053% | time: 0000000032 \n",
      "[epoch:001, iter:00280] Loss: 1.813 | Acc: 33.086% | time: 0000000033 \n",
      "[epoch:001, iter:00281] Loss: 1.812 | Acc: 33.135% | time: 0000000033 \n",
      "[epoch:001, iter:00282] Loss: 1.812 | Acc: 33.145% | time: 0000000033 \n",
      "[epoch:001, iter:00283] Loss: 1.812 | Acc: 33.160% | time: 0000000033 \n",
      "[epoch:001, iter:00284] Loss: 1.811 | Acc: 33.187% | time: 0000000033 \n",
      "[epoch:001, iter:00285] Loss: 1.810 | Acc: 33.207% | time: 0000000033 \n",
      "[epoch:001, iter:00286] Loss: 1.809 | Acc: 33.260% | time: 0000000033 \n",
      "[epoch:001, iter:00287] Loss: 1.808 | Acc: 33.281% | time: 0000000033 \n",
      "[epoch:001, iter:00288] Loss: 1.809 | Acc: 33.290% | time: 0000000033 \n",
      "[epoch:001, iter:00289] Loss: 1.808 | Acc: 33.321% | time: 0000000034 \n",
      "[epoch:001, iter:00290] Loss: 1.807 | Acc: 33.346% | time: 0000000034 \n",
      "[epoch:001, iter:00291] Loss: 1.806 | Acc: 33.387% | time: 0000000034 \n",
      "[epoch:001, iter:00292] Loss: 1.806 | Acc: 33.358% | time: 0000000034 \n",
      "[epoch:001, iter:00293] Loss: 1.806 | Acc: 33.388% | time: 0000000034 \n",
      "[epoch:001, iter:00294] Loss: 1.806 | Acc: 33.392% | time: 0000000034 \n",
      "[epoch:001, iter:00295] Loss: 1.805 | Acc: 33.432% | time: 0000000034 \n",
      "[epoch:001, iter:00296] Loss: 1.804 | Acc: 33.446% | time: 0000000034 \n",
      "[epoch:001, iter:00297] Loss: 1.804 | Acc: 33.460% | time: 0000000034 \n",
      "[epoch:001, iter:00298] Loss: 1.804 | Acc: 33.505% | time: 0000000035 \n",
      "[epoch:001, iter:00299] Loss: 1.803 | Acc: 33.513% | time: 0000000035 \n",
      "[epoch:001, iter:00300] Loss: 1.802 | Acc: 33.568% | time: 0000000035 \n",
      "[epoch:001, iter:00301] Loss: 1.801 | Acc: 33.612% | time: 0000000035 \n",
      "[epoch:001, iter:00302] Loss: 1.800 | Acc: 33.635% | time: 0000000035 \n",
      "[epoch:001, iter:00303] Loss: 1.799 | Acc: 33.679% | time: 0000000035 \n",
      "[epoch:001, iter:00304] Loss: 1.798 | Acc: 33.681% | time: 0000000035 \n",
      "[epoch:001, iter:00305] Loss: 1.797 | Acc: 33.714% | time: 0000000035 \n",
      "[epoch:001, iter:00306] Loss: 1.796 | Acc: 33.778% | time: 0000000036 \n",
      "[epoch:001, iter:00307] Loss: 1.795 | Acc: 33.810% | time: 0000000036 \n",
      "[epoch:001, iter:00308] Loss: 1.794 | Acc: 33.827% | time: 0000000036 \n",
      "[epoch:001, iter:00309] Loss: 1.793 | Acc: 33.839% | time: 0000000036 \n",
      "[epoch:001, iter:00310] Loss: 1.793 | Acc: 33.851% | time: 0000000036 \n",
      "[epoch:001, iter:00311] Loss: 1.792 | Acc: 33.858% | time: 0000000036 \n",
      "[epoch:001, iter:00312] Loss: 1.791 | Acc: 33.879% | time: 0000000036 \n",
      "[epoch:001, iter:00313] Loss: 1.790 | Acc: 33.931% | time: 0000000036 \n",
      "[epoch:001, iter:00314] Loss: 1.790 | Acc: 33.962% | time: 0000000036 \n",
      "[epoch:001, iter:00315] Loss: 1.789 | Acc: 33.948% | time: 0000000037 \n",
      "[epoch:001, iter:00316] Loss: 1.788 | Acc: 33.999% | time: 0000000037 \n",
      "[epoch:001, iter:00317] Loss: 1.787 | Acc: 34.030% | time: 0000000037 \n",
      "[epoch:001, iter:00318] Loss: 1.786 | Acc: 34.051% | time: 0000000037 \n",
      "[epoch:001, iter:00319] Loss: 1.786 | Acc: 34.066% | time: 0000000037 \n",
      "[epoch:001, iter:00320] Loss: 1.785 | Acc: 34.072% | time: 0000000037 \n",
      "[epoch:001, iter:00321] Loss: 1.784 | Acc: 34.102% | time: 0000000037 \n",
      "[epoch:001, iter:00322] Loss: 1.783 | Acc: 34.132% | time: 0000000037 \n",
      "[epoch:001, iter:00323] Loss: 1.781 | Acc: 34.201% | time: 0000000038 \n",
      "[epoch:001, iter:00324] Loss: 1.781 | Acc: 34.250% | time: 0000000038 \n",
      "[epoch:001, iter:00325] Loss: 1.780 | Acc: 34.293% | time: 0000000038 \n",
      "[epoch:001, iter:00326] Loss: 1.780 | Acc: 34.313% | time: 0000000038 \n",
      "[epoch:001, iter:00327] Loss: 1.780 | Acc: 34.332% | time: 0000000038 \n",
      "[epoch:001, iter:00328] Loss: 1.779 | Acc: 34.351% | time: 0000000038 \n",
      "[epoch:001, iter:00329] Loss: 1.778 | Acc: 34.399% | time: 0000000038 \n",
      "[epoch:001, iter:00330] Loss: 1.777 | Acc: 34.422% | time: 0000000038 \n",
      "[epoch:001, iter:00331] Loss: 1.777 | Acc: 34.427% | time: 0000000038 \n",
      "[epoch:001, iter:00332] Loss: 1.777 | Acc: 34.413% | time: 0000000039 \n",
      "[epoch:001, iter:00333] Loss: 1.776 | Acc: 34.427% | time: 0000000039 \n",
      "[epoch:001, iter:00334] Loss: 1.775 | Acc: 34.501% | time: 0000000039 \n",
      "[epoch:001, iter:00335] Loss: 1.774 | Acc: 34.524% | time: 0000000039 \n",
      "[epoch:001, iter:00336] Loss: 1.774 | Acc: 34.533% | time: 0000000039 \n",
      "[epoch:001, iter:00337] Loss: 1.773 | Acc: 34.551% | time: 0000000039 \n",
      "[epoch:001, iter:00338] Loss: 1.772 | Acc: 34.588% | time: 0000000039 \n",
      "[epoch:001, iter:00339] Loss: 1.771 | Acc: 34.633% | time: 0000000039 \n",
      "[epoch:001, iter:00340] Loss: 1.770 | Acc: 34.660% | time: 0000000039 \n",
      "[epoch:001, iter:00341] Loss: 1.769 | Acc: 34.700% | time: 0000000040 \n",
      "[epoch:001, iter:00342] Loss: 1.769 | Acc: 34.713% | time: 0000000040 \n",
      "[epoch:001, iter:00343] Loss: 1.768 | Acc: 34.726% | time: 0000000040 \n",
      "[epoch:001, iter:00344] Loss: 1.767 | Acc: 34.770% | time: 0000000040 \n",
      "[epoch:001, iter:00345] Loss: 1.766 | Acc: 34.792% | time: 0000000040 \n",
      "[epoch:001, iter:00346] Loss: 1.766 | Acc: 34.799% | time: 0000000040 \n",
      "[epoch:001, iter:00347] Loss: 1.765 | Acc: 34.839% | time: 0000000040 \n",
      "[epoch:001, iter:00348] Loss: 1.764 | Acc: 34.887% | time: 0000000040 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:001, iter:00349] Loss: 1.763 | Acc: 34.917% | time: 0000000041 \n",
      "[epoch:001, iter:00350] Loss: 1.763 | Acc: 34.920% | time: 0000000041 \n",
      "[epoch:001, iter:00351] Loss: 1.762 | Acc: 34.931% | time: 0000000041 \n",
      "[epoch:001, iter:00352] Loss: 1.760 | Acc: 34.965% | time: 0000000041 \n",
      "[epoch:001, iter:00353] Loss: 1.759 | Acc: 34.999% | time: 0000000041 \n",
      "[epoch:001, iter:00354] Loss: 1.759 | Acc: 35.015% | time: 0000000041 \n",
      "[epoch:001, iter:00355] Loss: 1.758 | Acc: 35.057% | time: 0000000041 \n",
      "[epoch:001, iter:00356] Loss: 1.757 | Acc: 35.086% | time: 0000000041 \n",
      "[epoch:001, iter:00357] Loss: 1.757 | Acc: 35.106% | time: 0000000041 \n",
      "[epoch:001, iter:00358] Loss: 1.757 | Acc: 35.121% | time: 0000000042 \n",
      "[epoch:001, iter:00359] Loss: 1.757 | Acc: 35.119% | time: 0000000042 \n",
      "[epoch:001, iter:00360] Loss: 1.756 | Acc: 35.139% | time: 0000000042 \n",
      "[epoch:001, iter:00361] Loss: 1.756 | Acc: 35.167% | time: 0000000042 \n",
      "[epoch:001, iter:00362] Loss: 1.755 | Acc: 35.204% | time: 0000000042 \n",
      "[epoch:001, iter:00363] Loss: 1.755 | Acc: 35.214% | time: 0000000042 \n",
      "[epoch:001, iter:00364] Loss: 1.755 | Acc: 35.229% | time: 0000000042 \n",
      "[epoch:001, iter:00365] Loss: 1.755 | Acc: 35.244% | time: 0000000042 \n",
      "[epoch:001, iter:00366] Loss: 1.755 | Acc: 35.220% | time: 0000000043 \n",
      "[epoch:001, iter:00367] Loss: 1.754 | Acc: 35.252% | time: 0000000043 \n",
      "[epoch:001, iter:00368] Loss: 1.754 | Acc: 35.275% | time: 0000000043 \n",
      "[epoch:001, iter:00369] Loss: 1.753 | Acc: 35.315% | time: 0000000043 \n",
      "[epoch:001, iter:00370] Loss: 1.752 | Acc: 35.325% | time: 0000000043 \n",
      "[epoch:001, iter:00371] Loss: 1.751 | Acc: 35.369% | time: 0000000043 \n",
      "[epoch:001, iter:00372] Loss: 1.751 | Acc: 35.383% | time: 0000000043 \n",
      "[epoch:001, iter:00373] Loss: 1.752 | Acc: 35.368% | time: 0000000043 \n",
      "[epoch:001, iter:00374] Loss: 1.751 | Acc: 35.382% | time: 0000000043 \n",
      "[epoch:001, iter:00375] Loss: 1.750 | Acc: 35.396% | time: 0000000044 \n",
      "[epoch:001, iter:00376] Loss: 1.750 | Acc: 35.439% | time: 0000000044 \n",
      "[epoch:001, iter:00377] Loss: 1.749 | Acc: 35.448% | time: 0000000044 \n",
      "[epoch:001, iter:00378] Loss: 1.749 | Acc: 35.454% | time: 0000000044 \n",
      "[epoch:001, iter:00379] Loss: 1.748 | Acc: 35.463% | time: 0000000044 \n",
      "[epoch:001, iter:00380] Loss: 1.747 | Acc: 35.535% | time: 0000000044 \n",
      "[epoch:001, iter:00381] Loss: 1.747 | Acc: 35.540% | time: 0000000044 \n",
      "[epoch:001, iter:00382] Loss: 1.746 | Acc: 35.565% | time: 0000000044 \n",
      "[epoch:001, iter:00383] Loss: 1.746 | Acc: 35.566% | time: 0000000045 \n",
      "[epoch:001, iter:00384] Loss: 1.745 | Acc: 35.616% | time: 0000000045 \n",
      "[epoch:001, iter:00385] Loss: 1.743 | Acc: 35.657% | time: 0000000045 \n",
      "[epoch:001, iter:00386] Loss: 1.743 | Acc: 35.670% | time: 0000000045 \n",
      "[epoch:001, iter:00387] Loss: 1.743 | Acc: 35.675% | time: 0000000045 \n",
      "[epoch:001, iter:00388] Loss: 1.742 | Acc: 35.692% | time: 0000000045 \n",
      "[epoch:001, iter:00389] Loss: 1.741 | Acc: 35.745% | time: 0000000045 \n",
      "[epoch:001, iter:00390] Loss: 1.740 | Acc: 35.773% | time: 0000000045 \n",
      "[epoch:001, iter:00391] Loss: 1.739 | Acc: 35.798% | time: 0000000045 \n",
      "[epoch:001, iter:00392] Loss: 1.739 | Acc: 35.814% | time: 0000000046 \n",
      "[epoch:001, iter:00393] Loss: 1.738 | Acc: 35.842% | time: 0000000046 \n",
      "[epoch:001, iter:00394] Loss: 1.737 | Acc: 35.858% | time: 0000000046 \n",
      "[epoch:001, iter:00395] Loss: 1.737 | Acc: 35.882% | time: 0000000046 \n",
      "[epoch:001, iter:00396] Loss: 1.736 | Acc: 35.886% | time: 0000000046 \n",
      "[epoch:001, iter:00397] Loss: 1.736 | Acc: 35.902% | time: 0000000046 \n",
      "[epoch:001, iter:00398] Loss: 1.735 | Acc: 35.910% | time: 0000000046 \n",
      "[epoch:001, iter:00399] Loss: 1.735 | Acc: 35.941% | time: 0000000046 \n",
      "[epoch:001, iter:00400] Loss: 1.734 | Acc: 35.980% | time: 0000000046 \n",
      "[epoch:001, iter:00401] Loss: 1.733 | Acc: 36.047% | time: 0000000047 \n",
      "[epoch:001, iter:00402] Loss: 1.732 | Acc: 36.070% | time: 0000000047 \n",
      "[epoch:001, iter:00403] Loss: 1.732 | Acc: 36.069% | time: 0000000047 \n",
      "[epoch:001, iter:00404] Loss: 1.731 | Acc: 36.112% | time: 0000000047 \n",
      "[epoch:001, iter:00405] Loss: 1.730 | Acc: 36.138% | time: 0000000047 \n",
      "[epoch:001, iter:00406] Loss: 1.730 | Acc: 36.153% | time: 0000000047 \n",
      "[epoch:001, iter:00407] Loss: 1.730 | Acc: 36.187% | time: 0000000047 \n",
      "[epoch:001, iter:00408] Loss: 1.729 | Acc: 36.217% | time: 0000000047 \n",
      "[epoch:001, iter:00409] Loss: 1.729 | Acc: 36.216% | time: 0000000048 \n",
      "[epoch:001, iter:00410] Loss: 1.728 | Acc: 36.231% | time: 0000000048 \n",
      "[epoch:001, iter:00411] Loss: 1.727 | Acc: 36.261% | time: 0000000048 \n",
      "[epoch:001, iter:00412] Loss: 1.726 | Acc: 36.321% | time: 0000000048 \n",
      "[epoch:001, iter:00413] Loss: 1.726 | Acc: 36.331% | time: 0000000048 \n",
      "[epoch:001, iter:00414] Loss: 1.725 | Acc: 36.345% | time: 0000000048 \n",
      "[epoch:001, iter:00415] Loss: 1.724 | Acc: 36.352% | time: 0000000048 \n",
      "[epoch:001, iter:00416] Loss: 1.724 | Acc: 36.384% | time: 0000000048 \n",
      "[epoch:001, iter:00417] Loss: 1.723 | Acc: 36.410% | time: 0000000048 \n",
      "[epoch:001, iter:00418] Loss: 1.723 | Acc: 36.401% | time: 0000000049 \n",
      "[epoch:001, iter:00419] Loss: 1.723 | Acc: 36.422% | time: 0000000049 \n",
      "[epoch:001, iter:00420] Loss: 1.723 | Acc: 36.432% | time: 0000000049 \n",
      "[epoch:001, iter:00421] Loss: 1.723 | Acc: 36.461% | time: 0000000049 \n",
      "[epoch:001, iter:00422] Loss: 1.723 | Acc: 36.460% | time: 0000000049 \n",
      "[epoch:001, iter:00423] Loss: 1.722 | Acc: 36.499% | time: 0000000049 \n",
      "[epoch:001, iter:00424] Loss: 1.721 | Acc: 36.527% | time: 0000000049 \n",
      "[epoch:001, iter:00425] Loss: 1.721 | Acc: 36.562% | time: 0000000049 \n",
      "[epoch:001, iter:00426] Loss: 1.720 | Acc: 36.579% | time: 0000000050 \n",
      "[epoch:001, iter:00427] Loss: 1.719 | Acc: 36.607% | time: 0000000050 \n",
      "[epoch:001, iter:00428] Loss: 1.720 | Acc: 36.606% | time: 0000000050 \n",
      "[epoch:001, iter:00429] Loss: 1.720 | Acc: 36.622% | time: 0000000050 \n",
      "[epoch:001, iter:00430] Loss: 1.719 | Acc: 36.664% | time: 0000000050 \n",
      "[epoch:001, iter:00431] Loss: 1.718 | Acc: 36.688% | time: 0000000050 \n",
      "[epoch:001, iter:00432] Loss: 1.718 | Acc: 36.712% | time: 0000000050 \n",
      "[epoch:001, iter:00433] Loss: 1.718 | Acc: 36.695% | time: 0000000050 \n",
      "[epoch:001, iter:00434] Loss: 1.717 | Acc: 36.740% | time: 0000000050 \n",
      "[epoch:001, iter:00435] Loss: 1.717 | Acc: 36.749% | time: 0000000051 \n",
      "[epoch:001, iter:00436] Loss: 1.717 | Acc: 36.758% | time: 0000000051 \n",
      "[epoch:001, iter:00437] Loss: 1.716 | Acc: 36.749% | time: 0000000051 \n",
      "[epoch:001, iter:00438] Loss: 1.716 | Acc: 36.765% | time: 0000000051 \n",
      "[epoch:001, iter:00439] Loss: 1.716 | Acc: 36.774% | time: 0000000051 \n",
      "[epoch:001, iter:00440] Loss: 1.715 | Acc: 36.797% | time: 0000000051 \n",
      "[epoch:001, iter:00441] Loss: 1.714 | Acc: 36.823% | time: 0000000051 \n",
      "[epoch:001, iter:00442] Loss: 1.713 | Acc: 36.853% | time: 0000000051 \n",
      "[epoch:001, iter:00443] Loss: 1.713 | Acc: 36.893% | time: 0000000052 \n",
      "[epoch:001, iter:00444] Loss: 1.712 | Acc: 36.930% | time: 0000000052 \n",
      "[epoch:001, iter:00445] Loss: 1.711 | Acc: 36.956% | time: 0000000052 \n",
      "[epoch:001, iter:00446] Loss: 1.710 | Acc: 36.978% | time: 0000000052 \n",
      "[epoch:001, iter:00447] Loss: 1.710 | Acc: 37.004% | time: 0000000052 \n",
      "[epoch:001, iter:00448] Loss: 1.710 | Acc: 37.008% | time: 0000000052 \n",
      "[epoch:001, iter:00449] Loss: 1.709 | Acc: 37.030% | time: 0000000052 \n",
      "[epoch:001, iter:00450] Loss: 1.709 | Acc: 37.059% | time: 0000000052 \n",
      "[epoch:001, iter:00451] Loss: 1.708 | Acc: 37.060% | time: 0000000052 \n",
      "[epoch:001, iter:00452] Loss: 1.708 | Acc: 37.064% | time: 0000000053 \n",
      "[epoch:001, iter:00453] Loss: 1.708 | Acc: 37.083% | time: 0000000053 \n",
      "[epoch:001, iter:00454] Loss: 1.707 | Acc: 37.121% | time: 0000000053 \n",
      "[epoch:001, iter:00455] Loss: 1.706 | Acc: 37.157% | time: 0000000053 \n",
      "[epoch:001, iter:00456] Loss: 1.705 | Acc: 37.202% | time: 0000000053 \n",
      "[epoch:001, iter:00457] Loss: 1.705 | Acc: 37.209% | time: 0000000053 \n",
      "[epoch:001, iter:00458] Loss: 1.704 | Acc: 37.251% | time: 0000000053 \n",
      "[epoch:001, iter:00459] Loss: 1.703 | Acc: 37.299% | time: 0000000053 \n",
      "[epoch:001, iter:00460] Loss: 1.702 | Acc: 37.313% | time: 0000000053 \n",
      "[epoch:001, iter:00461] Loss: 1.702 | Acc: 37.344% | time: 0000000054 \n",
      "[epoch:001, iter:00462] Loss: 1.701 | Acc: 37.385% | time: 0000000054 \n",
      "[epoch:001, iter:00463] Loss: 1.700 | Acc: 37.422% | time: 0000000054 \n",
      "[epoch:001, iter:00464] Loss: 1.700 | Acc: 37.423% | time: 0000000054 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:001, iter:00465] Loss: 1.699 | Acc: 37.470% | time: 0000000054 \n",
      "[epoch:001, iter:00466] Loss: 1.698 | Acc: 37.490% | time: 0000000054 \n",
      "[epoch:001, iter:00467] Loss: 1.698 | Acc: 37.500% | time: 0000000054 \n",
      "[epoch:001, iter:00468] Loss: 1.697 | Acc: 37.517% | time: 0000000054 \n",
      "[epoch:001, iter:00469] Loss: 1.697 | Acc: 37.540% | time: 0000000055 \n",
      "[epoch:001, iter:00470] Loss: 1.696 | Acc: 37.553% | time: 0000000055 \n",
      "[epoch:001, iter:00471] Loss: 1.696 | Acc: 37.570% | time: 0000000055 \n",
      "[epoch:001, iter:00472] Loss: 1.695 | Acc: 37.606% | time: 0000000055 \n",
      "[epoch:001, iter:00473] Loss: 1.695 | Acc: 37.612% | time: 0000000055 \n",
      "[epoch:001, iter:00474] Loss: 1.695 | Acc: 37.642% | time: 0000000055 \n",
      "[epoch:001, iter:00475] Loss: 1.694 | Acc: 37.668% | time: 0000000055 \n",
      "[epoch:001, iter:00476] Loss: 1.693 | Acc: 37.700% | time: 0000000055 \n",
      "[epoch:001, iter:00477] Loss: 1.692 | Acc: 37.719% | time: 0000000055 \n",
      "[epoch:001, iter:00478] Loss: 1.692 | Acc: 37.742% | time: 0000000056 \n",
      "[epoch:001, iter:00479] Loss: 1.692 | Acc: 37.748% | time: 0000000056 \n",
      "[epoch:001, iter:00480] Loss: 1.691 | Acc: 37.796% | time: 0000000056 \n",
      "[epoch:001, iter:00481] Loss: 1.690 | Acc: 37.828% | time: 0000000056 \n",
      "[epoch:001, iter:00482] Loss: 1.689 | Acc: 37.860% | time: 0000000056 \n",
      "[epoch:001, iter:00483] Loss: 1.688 | Acc: 37.891% | time: 0000000056 \n",
      "[epoch:001, iter:00484] Loss: 1.687 | Acc: 37.929% | time: 0000000056 \n",
      "[epoch:001, iter:00485] Loss: 1.687 | Acc: 37.938% | time: 0000000056 \n",
      "[epoch:001, iter:00486] Loss: 1.687 | Acc: 37.950% | time: 0000000057 \n",
      "[epoch:001, iter:00487] Loss: 1.687 | Acc: 37.968% | time: 0000000057 \n",
      "[epoch:001, iter:00488] Loss: 1.686 | Acc: 37.983% | time: 0000000057 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-77:\n",
      "Process Process-76:\n",
      "Process Process-80:\n",
      "Process Process-82:\n",
      "Process Process-78:\n",
      "Process Process-75:\n",
      "Process Process-79:\n",
      "Traceback (most recent call last):\n",
      "Process Process-81:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    racquire()\n",
      "    racquire()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "    racquire()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "    racquire()\n",
      "    img = self.transform(img)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "    buf = self.recv_bytes()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:001, iter:00489] Loss: 1.686 | Acc: 37.986% | time: 0000000057 \n",
      "[epoch:001, iter:00490] Loss: 1.686 | Acc: 37.978% | time: 0000000057 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/transforms/functional.py\", line 83, in to_tensor\n",
      "    return img.float().div(255)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception socket.error: error(2, 'No such file or directory') in <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7fbc9a5a9e50>> ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5b781261ead7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# print loss and accuracy every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#         pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34mr\"\"\"Returns a CPU copy of this tensor if it's not already on the CPU\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### check usage\n",
    "\n",
    "aa = []\n",
    "bb=np.zeros(2000).reshape(20,100)\n",
    "print(bb.shape)\n",
    "aa.append(bb)\n",
    "aa = np.asarray(aa)\n",
    "aa.shape[0] * aa.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
